{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TTA Debug Notebook\n",
    "Structured visualisation to inspect TTA training input, step losses, and prediction evolution.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "ROOT = Path.cwd().parent\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT))\n",
    "SAM2_ROOT = ROOT.parent / \"sam2\"\n",
    "if SAM2_ROOT.exists() and str(SAM2_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(SAM2_ROOT))\n",
    "\n",
    "from configs.pipeline_config import load_pipeline_config\n",
    "from debug_tests.debug_test import MAIN_DIR, _load_constants\n",
    "from image_processings.tta import TTAPipeline, TTALossWeights\n",
    "from image_processings.tta.tta_core import default_multi_view_augment\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def _to_uint8(image):\n",
    "    if image.dtype == np.uint8:\n",
    "        return image\n",
    "    img = image.astype(np.float32)\n",
    "    if img.max() > img.min():\n",
    "        img = (img - img.min()) / (img.max() - img.min())\n",
    "    return (img * 255).clip(0, 255).astype(np.uint8)\n",
    "\n",
    "def _overlay(image, mask, color=(255, 0, 0), alpha=0.4):\n",
    "    base = _to_uint8(image).copy()\n",
    "    if base.ndim == 2:\n",
    "        base = np.repeat(base[..., None], 3, axis=2)\n",
    "    overlay = base.copy()\n",
    "    overlay[mask] = color\n",
    "    return (base * (1 - alpha) + overlay * alpha).astype(np.uint8)\n",
    "\n",
    "def _save_image(path, image):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    plt.imsave(path, _to_uint8(image))\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Replace these placeholders with actual outputs from the main pipeline if needed.\n",
    "constants = _load_constants()\n",
    "pipeline_cfg = load_pipeline_config(MAIN_DIR / constants[\"pipeline_cfg\"])\n",
    "\n",
    "sample_name = \"sample_0001\"\n",
    "output_dir = Path(\"assets\") / \"tta_debug\" / sample_name\n",
    "\n",
    "pseudo_mask = np.zeros((64, 64), dtype=bool)  # pseudo label mask\n",
    "image = np.zeros((64, 64, 3), dtype=np.uint8)  # training input image\n",
    "prompts = {\n",
    "    \"point_coords\": np.array([[32, 32]], dtype=np.float32),\n",
    "    \"point_labels\": np.array([1], dtype=np.int64),\n",
    "    \"box\": None,\n",
    "    \"mask_input\": None,\n",
    "    \"multimask_output\": False,\n",
    "}\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "# Dummy predictor with required API; replace with SAM2 predictor in practice\n",
    "class DummyPredictor:\n",
    "    def predict(self, point_coords, point_labels, box, mask_input, multimask_output, return_logits=False):\n",
    "        h, w = image.shape[:2]\n",
    "        logits = np.random.randn(1, h, w).astype(np.float32)\n",
    "        return logits, [1.0], None\n",
    "\n",
    "predictor = DummyPredictor()\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1) Training input visualisation (original + augmented candidates)\n",
    "augment_fn = default_multi_view_augment(scales=(0.75, 1.0, 1.25), do_flip=True)\n",
    "candidates = augment_fn(image)\n",
    "\n",
    "# Evaluate candidates with a simple score: mean prob on pseudo-mask after align-back.\n",
    "candidate_scores = []\n",
    "for img_aug, align_back in candidates:\n",
    "    logits, _, _ = predictor.predict(\n",
    "        point_coords=prompts[\"point_coords\"],\n",
    "        point_labels=prompts[\"point_labels\"],\n",
    "        box=prompts[\"box\"],\n",
    "        mask_input=prompts[\"mask_input\"],\n",
    "        multimask_output=prompts[\"multimask_output\"],\n",
    "        return_logits=True,\n",
    "    )\n",
    "    probs = sigmoid(logits[0])\n",
    "    aligned = align_back(probs)\n",
    "    score = float(np.mean(aligned[pseudo_mask])) if pseudo_mask.any() else float(np.mean(aligned))\n",
    "    candidate_scores.append(score)\n",
    "\n",
    "best_idx = int(np.argmax(candidate_scores)) if candidate_scores else -1\n",
    "\n",
    "fig, axes = plt.subplots(1, max(1, len(candidates)), figsize=(4 * max(1, len(candidates)), 4))\n",
    "if len(candidates) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for idx, (img_aug, _) in enumerate(candidates):\n",
    "    title = f\"candidate {idx}\"\n",
    "    if idx == 0:\n",
    "        title += \" (train input)\"\n",
    "    if idx == best_idx:\n",
    "        title += \" (best)\"\n",
    "    axes[idx].imshow(_to_uint8(img_aug))\n",
    "    axes[idx].set_title(title)\n",
    "    axes[idx].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "_save_image(output_dir / \"candidates_grid.png\", np.array(fig.canvas.renderer.buffer_rgba()))\n",
    "plt.show()\n",
    "\n",
    "_save_image(output_dir / \"train_input.png\", image)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 2) Three-step training process with loss breakdown\n",
    "pipeline = TTAPipeline(\n",
    "    predictor=predictor,\n",
    "    loss_weights=TTALossWeights(anchor=1.0, entropy=0.1, consistency=0.5),\n",
    "    augment_fn=augment_fn,\n",
    ")\n",
    "\n",
    "step_outputs = []\n",
    "for step in range(3):\n",
    "    out = pipeline.step(image, prompts, pseudo_mask)\n",
    "    step_outputs.append(out)\n",
    "\n",
    "step_losses = []\n",
    "for idx, out in enumerate(step_outputs, start=1):\n",
    "    loss_dict = {k: float(v) for k, v in out.losses.items()}\n",
    "    loss_dict[\"step\"] = idx\n",
    "    step_losses.append(loss_dict)\n",
    "\n",
    "(output_dir / \"step_losses.json\").write_text(json.dumps(step_losses, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "# Print a small table for quick comparison\n",
    "headers = [\"step\", \"total\", \"anchor\", \"entropy\", \"consistency\"]\n",
    "print(\"\\t\".join(headers))\n",
    "for row in step_losses:\n",
    "    print(\"\\t\".join(str(row.get(h, \"\")) for h in headers))\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 3) Prediction evolution: per-step probs and overlays\n",
    "prob_maps = []\n",
    "overlays = []\n",
    "\n",
    "for out in step_outputs:\n",
    "    probs = out.student_probs\n",
    "    if hasattr(probs, \"detach\"):\n",
    "        probs = probs.detach().cpu().numpy()\n",
    "    if probs.ndim == 3 and probs.shape[0] == 1:\n",
    "        probs = probs[0]\n",
    "    prob_maps.append(probs)\n",
    "    overlays.append(_overlay(image, probs > 0.5))\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "for idx, probs in enumerate(prob_maps, start=1):\n",
    "    axes[idx - 1].imshow(probs, cmap=\"magma\")\n",
    "    axes[idx - 1].set_title(f\"step {idx} probs\")\n",
    "    axes[idx - 1].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "_save_image(output_dir / \"step_compare_probs.png\", np.array(fig.canvas.renderer.buffer_rgba()))\n",
    "plt.show()\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "for idx, overlay in enumerate(overlays, start=1):\n",
    "    axes[idx - 1].imshow(overlay)\n",
    "    axes[idx - 1].set_title(f\"step {idx} overlay\")\n",
    "    axes[idx - 1].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "_save_image(output_dir / \"step_compare_overlay.png\", np.array(fig.canvas.renderer.buffer_rgba()))\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}