{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TTA Debug Notebook (Aligned with run_tta.py)\n",
    "This notebook reuses the same pipeline + TTA flow as `debug_tests/run_tta.py` and runs on real data/model.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "ROOT = Path.cwd().parent\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT))\n",
    "SAM2_ROOT = ROOT.parent / \"sam2\"\n",
    "if SAM2_ROOT.exists() and str(SAM2_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(SAM2_ROOT))\n",
    "\n",
    "from configs.pipeline_config import load_pipeline_config\n",
    "from datasets.dataset import load_dataset\n",
    "from debug_tests.run_tta import (\n",
    "    _load_constants,\n",
    "    run_segmentation_with_info,\n",
    "    load_tta_config,\n",
    ")\n",
    "from image_processings.tta import TTALossWeights, run_tta_from_pool, default_multi_view_augment, apply_lora_to_mask_decoder\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def _to_uint8(image):\n",
    "    if image.dtype == np.uint8:\n",
    "        return image\n",
    "    img = image.astype(np.float32)\n",
    "    if img.max() > img.min():\n",
    "        img = (img - img.min()) / (img.max() - img.min())\n",
    "    return (img * 255).clip(0, 255).astype(np.uint8)\n",
    "\n",
    "def _overlay(image, mask, color=(255, 0, 0), alpha=0.4):\n",
    "    base = _to_uint8(image).copy()\n",
    "    if base.ndim == 2:\n",
    "        base = np.repeat(base[..., None], 3, axis=2)\n",
    "    overlay = base.copy()\n",
    "    overlay[mask] = color\n",
    "    return (base * (1 - alpha) + overlay * alpha).astype(np.uint8)\n",
    "\n",
    "def _save_image(path, image):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    plt.imsave(path, _to_uint8(image))\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load configs (same as run_tta.py)\n",
    "constants = _load_constants()\n",
    "pipeline_cfg = load_pipeline_config(ROOT / constants[\"pipeline_cfg\"])\n",
    "tta_cfg = load_tta_config(ROOT / \"configs\" / \"tta_config.json\")\n",
    "\n",
    "# Load dataset (same utility as run_tta.py)\n",
    "images, gt_masks, image_names = load_dataset(\n",
    "    pipeline_cfg.dataset.name,\n",
    "    data_root=None,\n",
    "    target_long_edge=pipeline_cfg.dataset.target_long_edge,\n",
    "    return_paths=True,\n",
    ")\n",
    "sample_idx = 0\n",
    "image = images[sample_idx]\n",
    "gt_mask = gt_masks[sample_idx]\n",
    "sample_name = Path(image_names[sample_idx]).stem if image_names else f\"sample_{sample_idx:04d}\"\n",
    "\n",
    "output_dir = ROOT / \"assets\" / \"tta_debug\" / sample_name\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Build model + predictor (same as run_tta.py)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = build_sam2(constants[\"model_cfg\"], constants[\"checkpoint\"], device=device)\n",
    "lora_cfg = tta_cfg.get(\"lora\", {})\n",
    "if lora_cfg.get(\"target\") == \"mask_decoder\":\n",
    "    apply_lora_to_mask_decoder(\n",
    "        model,\n",
    "        r=int(lora_cfg.get(\"rank\", 4)),\n",
    "        lora_alpha=int(lora_cfg.get(\"alpha\", 8)),\n",
    "        lora_dropout=float(lora_cfg.get(\"dropout\", 0.0)),\n",
    "        target_modules=lora_cfg.get(\"target_modules\"),\n",
    "    )\n",
    "predictor = SAM2ImagePredictor(model)\n",
    "predictor.model.to(device)\n",
    "model.train()\n",
    "\n",
    "trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = None\n",
    "if trainable_params:\n",
    "    opt_cfg = tta_cfg.get(\"optimizer\", {})\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        trainable_params,\n",
    "        lr=float(opt_cfg.get(\"lr\", 1e-4)),\n",
    "        weight_decay=float(opt_cfg.get(\"weight_decay\", 0.0)),\n",
    "    )\n",
    "max_grad_norm = float(tta_cfg.get(\"optimizer\", {}).get(\"max_grad_norm\", 1.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1) Run pipeline once to get prompts + mask pool (aligned with run_tta.py)\n",
    "base_mask, history, vis_image, segments, info = run_segmentation_with_info(image, pipeline_cfg, predictor)\n",
    "final_prompts = history[-1].prompts\n",
    "\n",
    "prompts = {\n",
    "    \"point_coords\": final_prompts.points,\n",
    "    \"point_labels\": final_prompts.labels,\n",
    "    \"box\": None,\n",
    "    \"mask_input\": None,\n",
    "    \"multimask_output\": pipeline_cfg.sam.multimask_output,\n",
    "}\n",
    "\n",
    "_save_image(output_dir / \"train_input.png\", vis_image)\n",
    "\n",
    "plt.imshow(_to_uint8(vis_image))\n",
    "plt.title(\"Training input (pipeline resized)\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 2) Candidate/augmentation grid (aligned with TTA augment function)\n",
    "augment_fn = default_multi_view_augment(\n",
    "    scales=tta_cfg[\"augment\"][\"scales\"],\n",
    "    do_flip=tta_cfg[\"augment\"][\"use_flip\"],\n",
    ")\n",
    "candidates = augment_fn(vis_image)\n",
    "\n",
    "# Simple score: mean prob over pseudo-mask (if any) after align-back\n",
    "pseudo_mask = info.get_mask_pool()[0][\"mask\"] if info.get_mask_pool() else base_mask\n",
    "candidate_scores = []\n",
    "for img_aug, align_back in candidates:\n",
    "    logits, _, _ = predictor.predict(\n",
    "        point_coords=prompts[\"point_coords\"],\n",
    "        point_labels=prompts[\"point_labels\"],\n",
    "        box=prompts[\"box\"],\n",
    "        mask_input=prompts[\"mask_input\"],\n",
    "        multimask_output=prompts[\"multimask_output\"],\n",
    "        return_logits=True,\n",
    "    )\n",
    "    probs = 1.0 / (1.0 + np.exp(-logits[0]))\n",
    "    aligned = align_back(probs)\n",
    "    score = float(np.mean(aligned[pseudo_mask])) if pseudo_mask.any() else float(np.mean(aligned))\n",
    "    candidate_scores.append(score)\n",
    "\n",
    "best_idx = int(np.argmax(candidate_scores)) if candidate_scores else -1\n",
    "\n",
    "fig, axes = plt.subplots(1, max(1, len(candidates)), figsize=(4 * max(1, len(candidates)), 4))\n",
    "if len(candidates) == 1:\n",
    "    axes = [axes]\n",
    "for idx, (img_aug, _) in enumerate(candidates):\n",
    "    title = f\"candidate {idx}\"\n",
    "    if idx == 0:\n",
    "        title += \" (train input)\"\n",
    "    if idx == best_idx:\n",
    "        title += \" (best)\"\n",
    "    axes[idx].imshow(_to_uint8(img_aug))\n",
    "    axes[idx].set_title(title)\n",
    "    axes[idx].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "_save_image(output_dir / \"candidates_grid.png\", np.array(fig.canvas.renderer.buffer_rgba()))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 3) Run TTA steps with real model, collect losses + outputs\n",
    "tta_loss_weights = TTALossWeights(\n",
    "    anchor=float(tta_cfg[\"loss_weights\"][\"anchor\"]),\n",
    "    entropy=float(tta_cfg[\"loss_weights\"][\"entropy\"]),\n",
    "    consistency=float(tta_cfg[\"loss_weights\"][\"consistency\"]),\n",
    "    regularization=float(tta_cfg[\"loss_weights\"].get(\"regularization\", 0.0)),\n",
    ")\n",
    "\n",
    "def _optimizer_step(total_loss, _losses):\n",
    "    if optimizer is None:\n",
    "        return\n",
    "    if not isinstance(total_loss, torch.Tensor) or not total_loss.requires_grad:\n",
    "        return\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    total_loss.backward()\n",
    "    if max_grad_norm > 0:\n",
    "        nn.utils.clip_grad_norm_(trainable_params, max_grad_norm)\n",
    "    optimizer.step()\n",
    "\n",
    "step_outputs = []\n",
    "step_losses = []\n",
    "for step in range(int(tta_cfg.get(\"tta_steps\", 3))):\n",
    "    tta_out = run_tta_from_pool(\n",
    "        predictor,\n",
    "        vis_image,\n",
    "        info.get_mask_pool(),\n",
    "        prompts,\n",
    "        loss_weights=tta_loss_weights,\n",
    "        selection_strategy=tta_cfg.get(\"pseudo_label\", {}).get(\"strategy\", \"score_top_k\"),\n",
    "        top_k=int(tta_cfg.get(\"pseudo_label\", {}).get(\"top_k_masks\", 3)),\n",
    "        augment_fn=augment_fn,\n",
    "        optimizer_step_fn=_optimizer_step,\n",
    "    )\n",
    "    step_outputs.append(tta_out[\"tta_outputs\"])\n",
    "    step_losses.append({\"step\": step + 1, **{k: float(v) for k, v in tta_out[\"tta_outputs\"].losses.items()}})\n",
    "\n",
    "(output_dir / \"step_losses.json\").write_text(json.dumps(step_losses, indent=2), encoding=\"utf-8\")\n",
    "print(json.dumps(step_losses, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 4) Prediction evolution (step1 -> step3)\n",
    "prob_maps = []\n",
    "overlays = []\n",
    "\n",
    "for out in step_outputs:\n",
    "    probs = out.student_probs\n",
    "    if hasattr(probs, \"detach\"):\n",
    "        probs = probs.detach().cpu().numpy()\n",
    "    if probs.ndim == 3 and probs.shape[0] == 1:\n",
    "        probs = probs[0]\n",
    "    prob_maps.append(probs)\n",
    "    overlays.append(_overlay(vis_image, probs > 0.5))\n",
    "\n",
    "fig, axes = plt.subplots(1, len(prob_maps), figsize=(4 * len(prob_maps), 4))\n",
    "if len(prob_maps) == 1:\n",
    "    axes = [axes]\n",
    "for idx, probs in enumerate(prob_maps, start=1):\n",
    "    axes[idx - 1].imshow(probs, cmap=\"magma\")\n",
    "    axes[idx - 1].set_title(f\"step {idx} probs\")\n",
    "    axes[idx - 1].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "_save_image(output_dir / \"step_compare_probs.png\", np.array(fig.canvas.renderer.buffer_rgba()))\n",
    "plt.show()\n",
    "\n",
    "fig, axes = plt.subplots(1, len(overlays), figsize=(4 * len(overlays), 4))\n",
    "if len(overlays) == 1:\n",
    "    axes = [axes]\n",
    "for idx, overlay in enumerate(overlays, start=1):\n",
    "    axes[idx - 1].imshow(overlay)\n",
    "    axes[idx - 1].set_title(f\"step {idx} overlay\")\n",
    "    axes[idx - 1].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "_save_image(output_dir / \"step_compare_overlay.png\", np.array(fig.canvas.renderer.buffer_rgba()))\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}