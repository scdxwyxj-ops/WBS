{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TTA Debug Notebook (Aligned with run_tta.py)\n",
    "This notebook reuses the same pipeline + TTA flow as `debug_tests/run_tta.py` and runs on real data/model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dc7b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from skimage.transform import resize\n",
    "\n",
    "ROOT = Path.cwd().parent\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT))\n",
    "SAM2_ROOT = ROOT.parent / \"sam2\"\n",
    "if SAM2_ROOT.exists() and str(SAM2_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(SAM2_ROOT))\n",
    "\n",
    "from configs.pipeline_config import load_pipeline_config\n",
    "from datasets.dataset import load_dataset\n",
    "from debug_tests.run_tta import (\n",
    "    _load_constants,\n",
    "    run_segmentation_with_info,\n",
    "    load_tta_config,\n",
    ")\n",
    "from image_processings.tta import (\n",
    "    TTALossWeights,\n",
    "    run_tta_from_pool,\n",
    "    default_multi_view_augment,\n",
    "    apply_lora_to_mask_decoder,\n",
    "    prepare_prompts_for_model,\n",
    "    prepare_prompts_for_vis,\n",
    ")\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def _to_uint8(image):\n",
    "    if image.dtype == np.uint8:\n",
    "        return image\n",
    "    img = image.astype(np.float32)\n",
    "    if img.max() > img.min():\n",
    "        img = (img - img.min()) / (img.max() - img.min())\n",
    "    return (img * 255).clip(0, 255).astype(np.uint8)\n",
    "\n",
    "def _overlay(image, mask, color=(255, 0, 0), alpha=0.4):\n",
    "    base = _to_uint8(image).copy()\n",
    "    if base.ndim == 2:\n",
    "        base = np.repeat(base[..., None], 3, axis=2)\n",
    "    mask_arr = mask\n",
    "    if mask_arr.shape[:2] != base.shape[:2]:\n",
    "        mask_arr = resize(mask_arr.astype(float), base.shape[:2], order=0, preserve_range=True, anti_aliasing=False) > 0.5\n",
    "    overlay = base.copy()\n",
    "    overlay[mask_arr] = color\n",
    "    return (base * (1 - alpha) + overlay * alpha).astype(np.uint8)\n",
    "\n",
    "def _draw_points(ax, points, labels):\n",
    "    if points is None or labels is None:\n",
    "        return\n",
    "    if len(points) == 0:\n",
    "        return\n",
    "    pts = np.asarray(points)\n",
    "    labs = np.asarray(labels)\n",
    "    pos = pts[labs == 1]\n",
    "    neg = pts[labs == 0]\n",
    "    if len(pos):\n",
    "        ax.scatter(pos[:, 0], pos[:, 1], s=30, c=\"lime\", marker=\"+\")\n",
    "    if len(neg):\n",
    "        ax.scatter(neg[:, 0], neg[:, 1], s=30, c=\"red\", marker=\"x\")\n",
    "\n",
    "def _show_heatmap(ax, heat, title):\n",
    "    if hasattr(heat, \"detach\"):\n",
    "        heat = heat.detach().cpu().numpy()\n",
    "    if heat.ndim == 3 and heat.shape[0] == 1:\n",
    "        heat = heat[0]\n",
    "    ax.imshow(heat, cmap=\"magma\")\n",
    "    ax.set_title(title)\n",
    "    ax.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877a769f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configs (same as run_tta.py)\n",
    "constants = _load_constants()\n",
    "pipeline_cfg = load_pipeline_config(ROOT / constants[\"pipeline_cfg\"])\n",
    "tta_cfg = load_tta_config(ROOT / \"configs\" / \"tta_config.json\")\n",
    "\n",
    "# Load dataset (same utility as run_tta.py)\n",
    "images, gt_masks, image_names = load_dataset(\n",
    "    pipeline_cfg.dataset.name,\n",
    "    data_root=None,\n",
    "    target_long_edge=pipeline_cfg.dataset.target_long_edge,\n",
    "    return_paths=True,\n",
    ")\n",
    "sample_idx = 0\n",
    "image = images[sample_idx]\n",
    "gt_mask = gt_masks[sample_idx]\n",
    "sample_name = Path(image_names[sample_idx]).stem if image_names else f\"sample_{sample_idx:04d}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9880cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model + predictor (same as run_tta.py)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = build_sam2(constants[\"model_cfg\"], constants[\"checkpoint\"], device=device)\n",
    "lora_cfg = tta_cfg.get(\"lora\", {})\n",
    "if lora_cfg.get(\"target\") == \"mask_decoder\":\n",
    "    apply_lora_to_mask_decoder(\n",
    "        model,\n",
    "        r=int(lora_cfg.get(\"rank\", 4)),\n",
    "        lora_alpha=int(lora_cfg.get(\"alpha\", 8)),\n",
    "        lora_dropout=float(lora_cfg.get(\"dropout\", 0.0)),\n",
    "        target_modules=lora_cfg.get(\"target_modules\"),\n",
    "    )\n",
    "predictor = SAM2ImagePredictor(model)\n",
    "predictor.model.to(device)\n",
    "model.train()\n",
    "\n",
    "trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = None\n",
    "if trainable_params:\n",
    "    opt_cfg = tta_cfg.get(\"optimizer\", {})\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        trainable_params,\n",
    "        lr=float(opt_cfg.get(\"lr\", 1e-4)),\n",
    "        weight_decay=float(opt_cfg.get(\"weight_decay\", 0.0)),\n",
    "    )\n",
    "max_grad_norm = float(tta_cfg.get(\"optimizer\", {}).get(\"max_grad_norm\", 1.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f2b7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Run pipeline once to get prompts + mask pool (aligned with run_tta.py)\n",
    "base_mask, history, vis_image, segments, info = run_segmentation_with_info(image, pipeline_cfg, predictor)\n",
    "final_prompts = history[-1].prompts\n",
    "mask_prompt_source = tta_cfg.get(\"prompt\", {}).get(\"mask_prompt_source\", \"none\")\n",
    "if mask_prompt_source in {\"pipeline_mask_prompt\", \"mask_prompt\"}:\n",
    "    tta_mask_input = final_prompts.mask_prompt\n",
    "elif mask_prompt_source in {\"pipeline_low_res\", \"low_res\"}:\n",
    "    tta_mask_input = final_prompts.low_res_mask\n",
    "else:\n",
    "    tta_mask_input = None\n",
    "\n",
    "prompts = {\n",
    "    \"point_coords\": final_prompts.points,\n",
    "    \"point_labels\": final_prompts.labels,\n",
    "    \"box\": None,\n",
    "    \"mask_input\": tta_mask_input,\n",
    "    \"multimask_output\": pipeline_cfg.sam.multimask_output,\n",
    "}\n",
    "\n",
    "\n",
    "plt.imshow(_to_uint8(vis_image))\n",
    "plt.title(\"Training input (pipeline resized)\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2445d9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline evolution: per-step prompts + logits + mask + mask_prompt\n",
    "max_steps = None  # set an int to limit, e.g., 6\n",
    "steps = history if max_steps is None else history[:max_steps]\n",
    "\n",
    "num_steps = len(steps)\n",
    "fig, axes = plt.subplots(num_steps, 4, figsize=(16, 4 * num_steps))\n",
    "if num_steps == 1:\n",
    "    axes = np.expand_dims(axes, axis=0)\n",
    "\n",
    "for row, step in enumerate(steps):\n",
    "    # Image + prompts\n",
    "    axes[row, 0].imshow(_to_uint8(vis_image))\n",
    "    _draw_points(axes[row, 0], step.prompts.points, step.prompts.labels)\n",
    "    axes[row, 0].set_title(f\"step {row}: prompts\")\n",
    "    axes[row, 0].axis(\"off\")\n",
    "\n",
    "    # Logits heatmap\n",
    "    _show_heatmap(axes[row, 1], step.logits, f\"step {row}: logits\")\n",
    "\n",
    "    # Mask overlay\n",
    "    overlay = _overlay(vis_image, step.mask)\n",
    "    axes[row, 2].imshow(overlay)\n",
    "    axes[row, 2].set_title(f\"step {row}: mask\")\n",
    "    axes[row, 2].axis(\"off\")\n",
    "\n",
    "    # Mask prompt (if any)\n",
    "    mask_prompt = step.prompts.mask_prompt\n",
    "    if mask_prompt is not None:\n",
    "        _show_heatmap(axes[row, 3], mask_prompt, f\"step {row}: mask_prompt\")\n",
    "    else:\n",
    "        axes[row, 3].text(0.5, 0.5, \"None\", ha=\"center\", va=\"center\")\n",
    "        axes[row, 3].set_title(f\"step {row}: mask_prompt\")\n",
    "        axes[row, 3].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91951ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask pool overview + best mask\n",
    "pool = info.get_mask_pool()\n",
    "areas = []\n",
    "for entry in pool:\n",
    "    mask = entry.get(\"mask\")\n",
    "    area = float(mask.sum()) if mask is not None else 0.0\n",
    "    areas.append(area)\n",
    "\n",
    "# Sort pool by area to show the interval progression\n",
    "sorted_idx = np.argsort(areas)\n",
    "sorted_pool = [pool[i] for i in sorted_idx]\n",
    "\n",
    "num = len(sorted_pool)\n",
    "cols = min(4, max(1, num))\n",
    "rows = int(np.ceil(num / cols)) if num else 1\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(4 * cols, 4 * rows))\n",
    "axes = np.atleast_1d(axes).reshape(rows, cols)\n",
    "\n",
    "for i, entry in enumerate(sorted_pool):\n",
    "    r, c = divmod(i, cols)\n",
    "    mask = entry.get(\"mask\")\n",
    "    score = entry.get(\"score\")\n",
    "    title = f\"pool {i} | area={int(areas[sorted_idx[i]])}\"\n",
    "    if score is not None:\n",
    "        title += f\" | score={score:.3f}\"\n",
    "    axes[r, c].imshow(mask, cmap=\"gray\")\n",
    "    axes[r, c].set_title(title)\n",
    "    axes[r, c].axis(\"off\")\n",
    "\n",
    "# Hide extra axes\n",
    "for j in range(num, rows * cols):\n",
    "    r, c = divmod(j, cols)\n",
    "    axes[r, c].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Best mask (final selection)\n",
    "best_overlay = _overlay(vis_image, base_mask)\n",
    "plt.imshow(best_overlay)\n",
    "plt.title(f\"Best mask (selection: {info.selection_metadata.get('method')})\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c6efdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Candidate/augmentation grid: left=aug image+mapped prompts, middle=logits heatmap, right=mask overlay + mask_prompt\n",
    "augment_fn = default_multi_view_augment(\n",
    "    scales=tta_cfg[\"augment\"][\"scales\"],\n",
    "    do_flip=tta_cfg[\"augment\"][\"use_flip\"],\n",
    "    views_per_step=int(tta_cfg[\"augment\"].get(\"views_per_step\", 2)),\n",
    ")\n",
    "views = augment_fn(vis_image)\n",
    "\n",
    "fig, axes = plt.subplots(len(views), 4, figsize=(18, 4 * len(views)))\n",
    "if len(views) == 1:\n",
    "    axes = np.expand_dims(axes, axis=0)\n",
    "\n",
    "for idx, (img_aug, transform_view) in enumerate(views):\n",
    "    h, w = img_aug.shape[:2]\n",
    "    mapped_vis = prepare_prompts_for_vis(transform_view, prompts)\n",
    "    mapped_model = prepare_prompts_for_model(transform_view, prompts)\n",
    "\n",
    "    axes[idx, 0].imshow(_to_uint8(img_aug), interpolation=\"nearest\")\n",
    "    _draw_points(axes[idx, 0], mapped_vis[\"point_coords\"], mapped_vis[\"point_labels\"])\n",
    "    axes[idx, 0].set_title(f\"candidate {idx} | {h}x{w} | scale={transform_view.scale} | flip={transform_view.flip}\")\n",
    "    axes[idx, 0].axis(\"off\")\n",
    "\n",
    "    predictor.set_image(img_aug)\n",
    "    logits, _, _ = predictor.predict(\n",
    "        point_coords=mapped_model[\"point_coords\"],\n",
    "        point_labels=mapped_model[\"point_labels\"],\n",
    "        box=mapped_model[\"box\"],\n",
    "        mask_input=mapped_model[\"mask_input\"],\n",
    "        multimask_output=mapped_model[\"multimask_output\"],\n",
    "        return_logits=True,\n",
    "    )\n",
    "    heat = logits[0]\n",
    "    _show_heatmap(axes[idx, 1], heat, f\"candidate {idx} logits\")\n",
    "\n",
    "    mask = heat > 0\n",
    "    overlay = _overlay(img_aug, mask)\n",
    "    axes[idx, 2].imshow(overlay)\n",
    "    axes[idx, 2].set_title(f\"candidate {idx} mask\")\n",
    "    axes[idx, 2].axis(\"off\")\n",
    "\n",
    "    if mapped_vis[\"mask_input\"] is not None:\n",
    "        _show_heatmap(axes[idx, 3], mapped_vis[\"mask_input\"], f\"candidate {idx} mask_prompt\")\n",
    "    else:\n",
    "        axes[idx, 3].text(0.5, 0.5, \"None\", ha=\"center\", va=\"center\")\n",
    "        axes[idx, 3].set_title(f\"candidate {idx} mask_prompt\")\n",
    "        axes[idx, 3].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081e6f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Run TTA steps with real model, collect losses + outputs\n",
    "tta_loss_weights = TTALossWeights(\n",
    "    anchor=float(tta_cfg[\"loss_weights\"][\"anchor\"]),\n",
    "    entropy=float(tta_cfg[\"loss_weights\"][\"entropy\"]),\n",
    "    consistency=float(tta_cfg[\"loss_weights\"][\"consistency\"]),\n",
    "    regularization=float(tta_cfg[\"loss_weights\"].get(\"regularization\", 0.0)),\n",
    ")\n",
    "\n",
    "def _optimizer_step(total_loss, _losses):\n",
    "    if optimizer is None:\n",
    "        return\n",
    "    if not isinstance(total_loss, torch.Tensor) or not total_loss.requires_grad:\n",
    "        return\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    total_loss.backward()\n",
    "    if max_grad_norm > 0:\n",
    "        nn.utils.clip_grad_norm_(trainable_params, max_grad_norm)\n",
    "    optimizer.step()\n",
    "\n",
    "step_outputs = []\n",
    "step_losses = []\n",
    "for step in range(int(tta_cfg.get(\"tta_steps\", 3))):\n",
    "    tta_out = run_tta_from_pool(\n",
    "        predictor,\n",
    "        vis_image,\n",
    "        info.get_mask_pool(),\n",
    "        prompts,\n",
    "        loss_weights=tta_loss_weights,\n",
    "        selection_strategy=tta_cfg.get(\"pseudo_label\", {}).get(\"strategy\", \"score_top_k\"),\n",
    "        top_k=int(tta_cfg.get(\"pseudo_label\", {}).get(\"top_k_masks\", 3)),\n",
    "        augment_fn=augment_fn,\n",
    "        optimizer_step_fn=_optimizer_step,\n",
    "    )\n",
    "    step_outputs.append(tta_out[\"tta_outputs\"])\n",
    "    step_losses.append({\"step\": step + 1, **{k: float(v) for k, v in tta_out[\"tta_outputs\"].losses.items()}})\n",
    "\n",
    "print(json.dumps(step_losses, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb2e6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Prediction evolution (step1 -> step3)\n",
    "prob_maps = []\n",
    "overlays = []\n",
    "\n",
    "for out in step_outputs:\n",
    "    probs = out.student_probs\n",
    "    if hasattr(probs, \"detach\"):\n",
    "        probs = probs.detach().cpu().numpy()\n",
    "    if probs.ndim == 3 and probs.shape[0] == 1:\n",
    "        probs = probs[0]\n",
    "    prob_maps.append(probs)\n",
    "    overlays.append(_overlay(vis_image, probs > 0.5))\n",
    "\n",
    "fig, axes = plt.subplots(1, len(prob_maps), figsize=(4 * len(prob_maps), 4))\n",
    "if len(prob_maps) == 1:\n",
    "    axes = [axes]\n",
    "for idx, probs in enumerate(prob_maps, start=1):\n",
    "    axes[idx - 1].imshow(probs, cmap=\"magma\")\n",
    "    axes[idx - 1].set_title(f\"step {idx} probs\")\n",
    "    axes[idx - 1].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig, axes = plt.subplots(1, len(overlays), figsize=(4 * len(overlays), 4))\n",
    "if len(overlays) == 1:\n",
    "    axes = [axes]\n",
    "for idx, overlay in enumerate(overlays, start=1):\n",
    "    axes[idx - 1].imshow(overlay)\n",
    "    axes[idx - 1].set_title(f\"step {idx} overlay\")\n",
    "    axes[idx - 1].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}